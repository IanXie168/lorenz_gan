lorenz:
    K: 4
    J: 4
    h: 10.0
    b: 10.0
    c: 1.0
    F: 8.0
    time_step: 0.01
    num_steps: 1002000
    skip: 5
    burn_in: 2000
    train_test_split: 0.4
gan:
    structure: specified_random
    t_skip: 5
    x_skip: 1
    output: sample
    cond_inputs: ["X_t"]
    output_cols: ["Ux_t+1"]
    generator:
        num_cond_inputs: 1
        num_random_inputs: 1
        num_outputs: 1
        num_hidden_neurons: 8
        activation: selu
        l2_strength: 0.001
        use_dropout: 0
        noise_sd: 0.01
        min_exp: -1
        normalize: 1

    discriminator:
        num_cond_inputs: 1
        num_sample_inputs: 1
        activation: selu
        num_hidden_layers: 2
        num_hidden_neurons: 8
        l2_strength: 0.001
        use_dropout: 0
        dropout_alpha: 0.0
        use_noise: 1
        noise_sd: 0.01
    gan_path: ./exp_pierre
    batch_size: 1024
    gan_index: 0
    loss: binary_crossentropy
    learning_rate: 0.0001
    num_epochs: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
    metrics: ["accuracy"]
random_updater:
    out_file: ./exp_pierre/ar1_random_updater.pkl
histogram:
    num_x_bins: 30
    num_u_bins: 30
    out_file: ./exp_pierre/u_histogram.pkl
poly:
    num_terms: 3
    noise_type: additive
    out_file: ./exp_pierre/u_poly.pkl
poly_add:
    num_terms: 3
    out_file: ./exp_pierre/u_poly_add.pkl
ann_res:
  mean_inputs: 1
  hidden_layers: 2
  hidden_neurons: 16
  activation: selu
  l2_weight: 0.0001
  learning_rate: 0.01
  mean_loss: mse
  res_loss: mse
  noise_sd: 0.01
  beta_1: 0.99
  model_path: ./exp_pierre
  dropout_alpha: 0.0
  num_epochs: 30
  batch_size: 64
  val_split: 0.2
  verbose: 2
  model_config: 5
output_nc_file: ./exp_pierre/lorenz_output.nc
output_csv_file: ./exp_pierre/lorenz_combined_output.csv
